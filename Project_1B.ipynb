{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Data Modeling With Apache Cassandra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### This project, part of the [Udacity Data Engineering Nanodegree](https://www.udacity.com/course/data-engineer-nanodegree--nd027), consists of the creation of an ETL Data Pipeline using music streaming data files and Apache Cassandra. The purpose of this project is to model a Cassandra database structure using data from raw .csv files that will allow for the 3 queries outlined in Part II below.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "tags": []
   },
   "source": [
    "#### Import Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import cassandra\n",
    "import os\n",
    "import glob\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Here we are reading .csv files from the *event_data* directory into a list of file paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/joe/Desktop/Udacity_Data_Engineering/Part2_DataModeling/Lesson5_Project_DataModelingWithApacheCassandra\n"
     ]
    }
   ],
   "source": [
    "# checking your current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Get your current folder and subfolder event data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# Create a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "# join the file path and roots with the subdirectories using glob\n",
    "    # rewrote this because file_path_list was getting overwritten\n",
    "    # with the files in .ipynb_checkpoints - jrw\n",
    "    if not root.endswith('.ipynb_checkpoints'):\n",
    "        file_path_list = glob.glob(os.path.join(root,'*'))\n",
    "        # Uncomment to view a list of the files\n",
    "        # print(file_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Here we are extracting data from the above files to create a single file of the data we need for this exercise. The output is being written to *event_datafile_new.csv*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# initiating an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = []\n",
    "    \n",
    "# for every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "\n",
    "# reading csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # creating a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)\n",
    "        \n",
    " # extracting each data row one by one and append it        \n",
    "        for line in csvreader:\n",
    "            # print(line)\n",
    "            full_data_rows_list.append(line)\n",
    "            \n",
    "# uncomment the code below if you would like to get total number of rows \n",
    "# print(len(full_data_rows_list))\n",
    "# uncomment the code below if you would like to check to see what the list of event data rows will look like\n",
    "# print(full_data_rows_list)\n",
    "\n",
    "# creating a smaller event data csv file called event_datafile_full csv that will be used to insert data into the \\\n",
    "# Apache Cassandra tables\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6821\n"
     ]
    }
   ],
   "source": [
    "# check the number of rows in your csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Part II. Creating Tables and Queries in Apache Cassandra\n",
    "\n",
    "#### Now we are going to work with the CSV file titled <font color=red>event_datafile_new.csv</font>, located within the Workspace directory.  The event_datafile_new.csv contains the following columns: \n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n",
    "\n",
    "The image below is a screenshot of what the denormalized data should appear like in the <font color=red>**event_datafile_new.csv**</font> after the code above is run:<br>\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# This should make a connection to a Cassandra instance your local machine \n",
    "# (127.0.0.1)\n",
    "\n",
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster()\n",
    "\n",
    "# To establish connection and begin executing queries, need a session\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Creating a Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    session.execute(\n",
    "        \"\"\"\n",
    "        CREATE KEYSPACE IF NOT EXISTS music\n",
    "        WITH REPLICATION =\n",
    "        { 'class' : 'SimpleStrategy', 'replication_factor' : 1 }\n",
    "        \"\"\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Setting the Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "session.set_keyspace(\"music\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Tables in the Code Below Are Designed to Allow for the Following Queries:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 1. Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "\n",
    "\n",
    "#### 2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "    \n",
    "\n",
    "#### 3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Query 1\n",
    "The requirement for Query 1 is to fetch the artist, song title and song length using a combination of sessionId and itemInSession values. In this case, we are using the session_id field as the partition key and a combination of the session_id and item_in_session fields as the Composite Key for each row. The results of the query will return artist, song title and song length for a single itemInSession value within a sessionId."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create The Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    session.execute(\n",
    "        \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS session_plays\n",
    "            (\n",
    "                session_id INT,\n",
    "                item_in_session INT,\n",
    "                artist TEXT,\n",
    "                song TEXT, \n",
    "                length FLOAT,\n",
    "                PRIMARY KEY (session_id, item_in_session)\n",
    "            )\n",
    "        \"\"\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Insert Values into the Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Inserting Values\n"
     ]
    }
   ],
   "source": [
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO session_plays (session_id, item_in_session, artist, song, length) \"\n",
    "        query = query + \"VALUES (%s, %s, %s, %s, %s)\"\n",
    "        insert_vals =[int(line[8]), int(line[3]), line[0], line[9], float(line[5])]\n",
    "        session.execute(query, insert_vals)\n",
    "print(\"Finished Inserting Values\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Query the Table according to Query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      artist                             song      length\n",
      "0  Faithless  Music Matters (Mark Knight Dub)  495.307312\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT artist, song, length from session_plays WHERE session_id = 338 and item_in_session = 4\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "if not rows:\n",
    "    print(\"Not Found\")\n",
    "else:\n",
    "    df = pd.DataFrame(list(rows))\n",
    "    print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Query 2\n",
    "The requirement for Query 2 is to fetch the artist name, song, and first and last name of the user for all of the songs that a user played in a particular session. The where clause values for this query are *userId* and *sessionId*, and the results must be sorted ascending by *itemInSession* values. Based on these requirements, we are using a combination of `user_id` and `session_id` for the partition key, and `item_in_session` for the clustering key. This will allow for faster querying since `user_id` and `session_id` will be partitioned together, as well as the results be sorted ascending according to the values in the `item_in_session` field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create the Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "editable": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    session.execute(\n",
    "        \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS user_session_plays\n",
    "            (\n",
    "                user_id INT,\n",
    "                session_id INT,\n",
    "                item_in_session INT,\n",
    "                artist TEXT,\n",
    "                song TEXT,\n",
    "                first_name TEXT,\n",
    "                last_name TEXT,\n",
    "                PRIMARY KEY ((user_id, session_id), item_in_session)\n",
    "            )\n",
    "        \"\"\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Insert Values into the Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Inserting Values\n"
     ]
    }
   ],
   "source": [
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader)\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO user_session_plays (user_id, session_id, item_in_session, artist, song, first_name, last_name) \"\n",
    "        query = query + \"VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "        insert_vals =[int(line[10]), int(line[8]), int(line[3]), line[0], line[9], line[1], line[4]]\n",
    "        session.execute(query, insert_vals)\n",
    "print(\"Finished Inserting Values\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Query the Table According to Query 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              artist                                               song  \\\n",
      "0   Down To The Bone                                 Keep On Keepin' On   \n",
      "1       Three Drives                                        Greece 2000   \n",
      "2  Sebastien Tellier                                          Kilometer   \n",
      "3      Lonnie Gordon  Catch You Baby (Steve Pitron & Max Sanna Radio...   \n",
      "\n",
      "  first_name last_name  \n",
      "0     Sylvie      Cruz  \n",
      "1     Sylvie      Cruz  \n",
      "2     Sylvie      Cruz  \n",
      "3     Sylvie      Cruz  \n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT artist, song, first_name, last_name from user_session_plays WHERE user_id = 10 and session_id = 182\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "if not rows:\n",
    "    print(\"No Results Found\")\n",
    "else:\n",
    "    df = pd.DataFrame(list(rows))\n",
    "    print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Query 3\n",
    "The requirement for Query 3 is to fetch the first and last names of users that have ever played a particular song title. The where clause in this case will use a string that is the title of the song. In this case, we will use a Composite Key of *song* and *userId* for defining unique rows. We will also store the first and last names of the users according to each unique *userId*.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create the Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    session.execute(\n",
    "        \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS user_song_plays\n",
    "            (\n",
    "                song TEXT,\n",
    "                user_id INT,\n",
    "                first_name TEXT,\n",
    "                last_name TEXT,\n",
    "                PRIMARY KEY (song, user_id)\n",
    "            )\n",
    "        \"\"\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Insert Data into the Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Inserting Values\n"
     ]
    }
   ],
   "source": [
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader)\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO user_song_plays (song, user_id, first_name, last_name) \"\n",
    "        query = query + \"VALUES (%s, %s, %s, %s)\"\n",
    "        insert_vals =[line[9], int(line[10]), line[1], line[4]]\n",
    "        session.execute(query, insert_vals)\n",
    "print(\"Finished Inserting Values\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Query the Table According to Query 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   first_name last_name\n",
      "0  Jacqueline     Lynch\n",
      "1       Tegan    Levine\n",
      "2        Sara   Johnson\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT first_name, last_name from user_song_plays WHERE song = 'All Hands Against His Own'\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "if not rows:\n",
    "    print(\"No Results Found\")\n",
    "else:\n",
    "    df = pd.DataFrame(list(rows))\n",
    "    print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x7febdec17250>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.execute(\"DROP TABLE IF EXISTS session_plays\")\n",
    "session.execute(\"DROP TABLE IF EXISTS user_session_plays\")\n",
    "session.execute(\"DROP TABLE IF EXISTS user_song_plays\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Close the session and cluster connection¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
